{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Oil Prices Using an RNN with LSTM\n",
    "\n",
    "Researchers have found  that recurrent neural networks (RNN) with LSTM can outperform traditional forecasting models like ARIMA when  forecasting future values of certain  time series data. (For an example see [A comparison of artificial neural network and time series models for forecasting commodity prices](https://www.sciencedirect.com/science/article/pii/0925231295000208))\n",
    "\n",
    "This Python 3 notebook will demonstrate how to apply an RNN with LSTM to forecast weekly West Texas crude oil prices. The data used to train the model covers the time period  from 01/03/1986 to 3/30/2018. The data  was downloaded from the [Federal Reserve Bank of St. Louis](https://fred.stlouisfed.org)\n",
    "\n",
    "## Setup\n",
    "\n",
    "1. Download the file with West Texas crude oil prices  from [here](https://raw.githubusercontent.com/djccarew/timeseries-rnn-lab-part1/master/data/WCOILWTICO.csv) to your local system. The name of the file is WCOILWTICO.csv.\n",
    "\n",
    "2. Click on the data icon  at the top right of the notebook window and then select and upload the <b>WCOILWTCO.csv</b> file.\n",
    "![Data icon](https://github.com/djccarew/timeseries-rnn-lab-part1/raw/master/images/ss6.png) \n",
    "\n",
    "3. Once the file is uploaded, place your cursor in the code cell below and select <b>Insert to code->Insert pandas Dataframe</b>.\n",
    "![Insert code](https://github.com/djccarew/timeseries-rnn-lab-part1/raw/master/images/ss7.png) \n",
    "This will insert the code to load the file from  Object Storage into a DataFrame\n",
    "\n",
    "4. Run each cell in the notebook after reading the description of what is being done with each cell\n",
    "\n",
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With your cursor in this cell, insert the code to read the dataset into a DataFrame as instructed in step 3) \n",
    "# of the setup instructions above\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New version of imported DataFrame indexed by the DATE column\n",
    "# Make sure variable name on the right of the assigment statement matches the value inserted\n",
    "# into the code cell above\n",
    "data =  df_data_1.set_index('DATE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required imports\n",
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "from matplotlib import pyplot\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "import numpy as np\n",
    "py.init_notebook_mode(connected=True)\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data read in \n",
    "cop_trace = go.Scatter(x=data.index, y=data['WCOILWTICO'], name= 'Price')\n",
    "py.iplot([cop_trace])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scaled version of the data with oil prices normalized between 0 and 1\n",
    "values = data['WCOILWTICO'].values.reshape(-1,1)\n",
    "values = values.astype('float32')\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data between training and testing \n",
    "# The first 70% of the data is used for training while the remaining 30% is used for validation\n",
    "train_size = int(len(scaled) * 0.7)\n",
    "test_size = len(scaled) - train_size\n",
    "train, test = scaled[0:train_size,:], scaled[train_size:len(scaled),:]\n",
    "print(len(train), len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates the X and Y data from the downloaded dataset. The last n values in the input data are left off\n",
    "# and the Y values are generated by shifting the X values by n \n",
    "# where n is  the value of the prev_periods paramater\n",
    "\n",
    "# See the example below , prev_periods is set to 2\n",
    "# Original X (weeks 1 - 5) = 1.05, 1.15, 1.25, 1.35, 1.45\n",
    "# New X (weeks 1 - 3) = 1.05, 1.15, 1.25\n",
    "# Y = 1.25, 1.35, 1.45\n",
    "# \n",
    "def gen_datasets(dataset, prev_periods=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset) - prev_periods):\n",
    "        a = dataset[i:(i + prev_periods), 0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + prev_periods, 0])\n",
    "    print(len(dataY))\n",
    "    return np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate testing and validation data\n",
    "# We'll use a sliding window size of 1 week to predict the next week's price \n",
    "prev_periods = 1\n",
    "trainX, trainY = gen_datasets(train, prev_periods)\n",
    "testX, testY = gen_datasets(test, prev_periods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape into a numpy arraya of shape (m, 1, prev_periods) where m is the number of training or testing values\n",
    "trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build RNN - this should take a a few minutes\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mae'])\n",
    "history = model.fit(trainX, trainY, epochs=50, batch_size=32, validation_data=(testX, testY), verbose=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out MSE, RMSE, MAE for training and testing data\n",
    "training_error = model.evaluate(trainX, trainY, verbose=0)\n",
    "print('Training error: %.5f MSE (%.5f RMSE) %.5f MAE' % (training_error[0], sqrt(training_error[0]), training_error[1]))\n",
    "testing_error = model.evaluate(testX, testY, verbose=0)\n",
    "print('Testing error: %.5f MSE (%.5f RMSE) %.5f MAE' % (testing_error[0], sqrt(testing_error[0]), testing_error[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot validation loss  vs epoch number\n",
    "pyplot.plot(history.history['loss'], label='training loss')\n",
    "pyplot.plot(history.history['val_loss'], label='test loss')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot prediction vs actual using scaled values (0, 1)\n",
    "yhat_test = model.predict(testX)\n",
    "print(yhat_test.shape)\n",
    "pyplot.plot(yhat_test, color='red', label='prediction')\n",
    "pyplot.plot(testY, color='blue', label='actual')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert scaled prices back to original scale (USD)\n",
    "yhat_test_inverse = scaler.inverse_transform(yhat_test.reshape(-1, 1))\n",
    "testY_inverse = scaler.inverse_transform(testY.reshape(-1, 1))\n",
    "\n",
    "# Add dates back\n",
    "dates = data.tail(len(testX)).index\n",
    "testY_reshape = testY_inverse.reshape(len(testY_inverse))\n",
    "yhat_test_reshape = yhat_test_inverse.reshape(len(yhat_test_inverse))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate MSE< RMSE based on original USD prices\n",
    "mse = mean_squared_error(testY_inverse, yhat_test_inverse)\n",
    "rmse = sqrt(mse)\n",
    "print('Test MSE(USD): %.3f Test RMSE(USD): %.3f' % (mse, rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot actual vs predicted using actual dates and USD\n",
    "actual = go.Scatter(x=dates, y=testY_reshape, line = dict(color = ('rgb(0, 0, 255)'), width = 4), name= 'Actual Price')\n",
    "predicted = go.Scatter(x=dates, y=yhat_test_reshape, line = dict(color = ('rgb(255, 0, 0)'), width = 4), name= 'Predicted Price')\n",
    "py.iplot([predicted, actual])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run new data through model\n",
    "As part of the  data prep that last weeks price (3/30/2018) was left off because we had no data for the following week (4/6/2018). Let's use this value to predict the price for the week of 4/6/2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab last week of  normalized data and reshape into shape expected by model \n",
    "scaled_last_prices = scaled[len(scaled) - prev_periods:len(scaled),:]\n",
    "scaled_last_prices = np.reshape(scaled_last_prices, (1, 1, prev_periods))\n",
    "\n",
    "print(scaled_last_prices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the price for the week of 4/6/2018 using the model\n",
    "# Note this will be on a scale of (0,1)\n",
    "#print(new_scaled_last_prices.shape)\n",
    "next_price_prediction = model.predict(scaled_last_prices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform scaled predicion back to a USD price\n",
    "next_price_inverse = scaler.inverse_transform(next_price_prediction.reshape(-1, 1))\n",
    "print(next_price_inverse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations !!! You successfully built an RNN to forecast oil prices "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
